{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding Layer in TensorFlow/Keras\n",
    "\n",
    "## Overview\n",
    "This guide explains how to create an embedding layer in TensorFlow/Keras to convert words into dense numerical vectors. Instead of one-hot encoding, which is inefficient, we use an embedding layer to learn meaningful word representations.\n",
    "\n",
    "## Steps to Make Embedding Layers\n",
    "\n",
    "### 1️⃣ Define Sentences\n",
    "- **Action:** Create text data.\n",
    "- **Purpose:** Provides input for the model.\n",
    "\n",
    "```python\n",
    "sent = [\n",
    "    'the glass of milk',\n",
    "    'the glass of juice',\n",
    "    'the cup of tea',\n",
    "    'I am a good boy',\n",
    "    'I am a good developer',\n",
    "    'understand the meaning of words',\n",
    "    'your videos are good',\n",
    "]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 2️⃣ One-Hot Encoding\n",
    "- **Action:** Convert words to unique numbers.\n",
    "- **Purpose:** Makes words machine-readable.\n",
    "\n",
    "```python\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "voc_size = 10000  # Define vocabulary size\n",
    "onehot_repr = [one_hot(words, voc_size) for words in sent]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 3️⃣ Padding\n",
    "- **Action:** Make all sentences the same length.\n",
    "- **Purpose:** Required for neural networks.\n",
    "\n",
    "```python\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "\n",
    "fixed_length = 8  # Define the fixed sentence length\n",
    "padded_sentences = pad_sequences(onehot_repr, maxlen=fixed_length, padding='post')\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 4️⃣ Embedding Layer\n",
    "- **Action:** Convert words to dense vectors.\n",
    "- **Purpose:** Captures word relationships.\n",
    "\n",
    "```python\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=voc_size, output_dim=10, input_length=fixed_length),\n",
    "])\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 5️⃣ Model Compilation\n",
    "- **Action:** Prepare model for training.\n",
    "- **Purpose:** Allows learning word meanings.\n",
    "\n",
    "```python\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.summary()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 6️⃣ Prediction\n",
    "- **Action:** Generate embeddings.\n",
    "- **Purpose:** Outputs vector representations.\n",
    "\n",
    "```python\n",
    "embeddings = model.predict(padded_sentences)\n",
    "print(embeddings.shape)  # (7, 8, 10) -> 7 sentences, 8 words each, 10-d vector per word\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Why Use an Embedding Layer Instead of One-Hot Encoding?\n",
    "✅ One-hot encoding uses **huge sparse matrices** (wastes memory).\n",
    "✅ The embedding layer **learns relationships** (e.g., \"king\" and \"queen\" are similar).\n",
    "✅ It enables models to generalize across words and **understand meaning**.\n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "| **Step** | **Action** | **Purpose** |\n",
    "|----------|-----------|-------------|\n",
    "| 1️⃣ Define Sentences | Create text data | Provides input for the model |\n",
    "| 2️⃣ One-Hot Encoding | Convert words to unique numbers | Makes words machine-readable |\n",
    "| 3️⃣ Padding | Make all sentences the same length | Required for neural networks |\n",
    "| 4️⃣ Embedding Layer | Convert words to dense vectors | Captures word relationships |\n",
    "| 5️⃣ Model Compilation | Prepare model for training | Allows learning word meanings |\n",
    "| 6️⃣ Prediction | Generate embeddings | Outputs vector representations |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### sentences\n",
    "sent=[  'the glass of milk',\n",
    "     'the glass of juice',\n",
    "     'the cup of tea',\n",
    "    'I am a good boy',\n",
    "     'I am a good developer',\n",
    "     'understand the meaning of words',\n",
    "     'your videos are good',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the vocabulary size\n",
    "voc_size=10000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 19:57:41.799116: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "onehot_repr=[one_hot(words,voc_size)for words in sent]\n",
    "onehot_repr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4461, 7876, 5948, 4178],\n",
       " [4461, 7876, 5948, 8760],\n",
       " [4461, 6922, 5948, 774],\n",
       " [2667, 5741, 5824, 6347, 8747],\n",
       " [2667, 5741, 5824, 6347, 6316],\n",
       " [9838, 4461, 4740, 5948, 8085],\n",
       " [6486, 7058, 1200, 6347]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_repr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4461, 7876, 5948, 4178,    0,    0,    0,    0],\n",
       "       [4461, 7876, 5948, 8760,    0,    0,    0,    0],\n",
       "       [4461, 6922, 5948,  774,    0,    0,    0,    0],\n",
       "       [2667, 5741, 5824, 6347, 8747,    0,    0,    0],\n",
       "       [2667, 5741, 5824, 6347, 6316,    0,    0,    0],\n",
       "       [9838, 4461, 4740, 5948, 8085,    0,    0,    0],\n",
       "       [6486, 7058, 1200, 6347,    0,    0,    0,    0]], dtype=int32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply padding to make all sentences of same length\n",
    "fixed_length = 8\n",
    "padded_sentences = pad_sequences(onehot_repr, maxlen=fixed_length, padding='post')\n",
    "padded_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 8, 10)             100000    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 100000 (390.62 KB)\n",
      "Trainable params: 100000 (390.62 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(\n",
    "  [\n",
    "    Embedding(input_dim=voc_size, output_dim=10, input_length=fixed_length),\n",
    "  ]\n",
    ")\n",
    "model.compile('adam', 'mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 211ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 0.04333014,  0.02350302, -0.02824965,  0.01726067,\n",
       "          0.00651807, -0.0306138 , -0.03183967,  0.01574612,\n",
       "          0.03968767,  0.0188956 ],\n",
       "        [-0.0246981 , -0.04529704,  0.03991035,  0.02098986,\n",
       "          0.0012746 ,  0.00517123,  0.03313885, -0.00806148,\n",
       "          0.0284325 , -0.04138196],\n",
       "        [-0.01828529, -0.01818435,  0.02403356,  0.0450044 ,\n",
       "         -0.01886544,  0.04500891, -0.04477687,  0.00639769,\n",
       "          0.02108623, -0.02160677],\n",
       "        [ 0.01042484, -0.04008345, -0.0101433 , -0.01027871,\n",
       "         -0.02335546,  0.04838714, -0.02591652,  0.04670319,\n",
       "          0.04724597,  0.01240114],\n",
       "        [-0.03741231,  0.01323703, -0.04453991,  0.00029878,\n",
       "         -0.03997507, -0.01352666, -0.01122178, -0.02556491,\n",
       "         -0.03592603, -0.04666705],\n",
       "        [-0.03741231,  0.01323703, -0.04453991,  0.00029878,\n",
       "         -0.03997507, -0.01352666, -0.01122178, -0.02556491,\n",
       "         -0.03592603, -0.04666705],\n",
       "        [-0.03741231,  0.01323703, -0.04453991,  0.00029878,\n",
       "         -0.03997507, -0.01352666, -0.01122178, -0.02556491,\n",
       "         -0.03592603, -0.04666705],\n",
       "        [-0.03741231,  0.01323703, -0.04453991,  0.00029878,\n",
       "         -0.03997507, -0.01352666, -0.01122178, -0.02556491,\n",
       "         -0.03592603, -0.04666705]],\n",
       "\n",
       "       [[ 0.04333014,  0.02350302, -0.02824965,  0.01726067,\n",
       "          0.00651807, -0.0306138 , -0.03183967,  0.01574612,\n",
       "          0.03968767,  0.0188956 ],\n",
       "        [-0.0246981 , -0.04529704,  0.03991035,  0.02098986,\n",
       "          0.0012746 ,  0.00517123,  0.03313885, -0.00806148,\n",
       "          0.0284325 , -0.04138196],\n",
       "        [-0.01828529, -0.01818435,  0.02403356,  0.0450044 ,\n",
       "         -0.01886544,  0.04500891, -0.04477687,  0.00639769,\n",
       "          0.02108623, -0.02160677],\n",
       "        [ 0.00045824,  0.03232459,  0.01835711,  0.00368364,\n",
       "         -0.0470551 ,  0.02213999,  0.02599571, -0.02522403,\n",
       "         -0.03881625, -0.03770772],\n",
       "        [-0.03741231,  0.01323703, -0.04453991,  0.00029878,\n",
       "         -0.03997507, -0.01352666, -0.01122178, -0.02556491,\n",
       "         -0.03592603, -0.04666705],\n",
       "        [-0.03741231,  0.01323703, -0.04453991,  0.00029878,\n",
       "         -0.03997507, -0.01352666, -0.01122178, -0.02556491,\n",
       "         -0.03592603, -0.04666705],\n",
       "        [-0.03741231,  0.01323703, -0.04453991,  0.00029878,\n",
       "         -0.03997507, -0.01352666, -0.01122178, -0.02556491,\n",
       "         -0.03592603, -0.04666705],\n",
       "        [-0.03741231,  0.01323703, -0.04453991,  0.00029878,\n",
       "         -0.03997507, -0.01352666, -0.01122178, -0.02556491,\n",
       "         -0.03592603, -0.04666705]],\n",
       "\n",
       "       [[ 0.04333014,  0.02350302, -0.02824965,  0.01726067,\n",
       "          0.00651807, -0.0306138 , -0.03183967,  0.01574612,\n",
       "          0.03968767,  0.0188956 ],\n",
       "        [ 0.0424777 ,  0.04464233,  0.01431246,  0.00551089,\n",
       "          0.04863323,  0.01492632, -0.00999231,  0.0055096 ,\n",
       "          0.00245199,  0.04725002],\n",
       "        [-0.01828529, -0.01818435,  0.02403356,  0.0450044 ,\n",
       "         -0.01886544,  0.04500891, -0.04477687,  0.00639769,\n",
       "          0.02108623, -0.02160677],\n",
       "        [-0.01842647, -0.02825681,  0.02295918,  0.0297381 ,\n",
       "          0.03363386,  0.00312791,  0.02736086, -0.02099071,\n",
       "          0.00619673,  0.04364796],\n",
       "        [-0.03741231,  0.01323703, -0.04453991,  0.00029878,\n",
       "         -0.03997507, -0.01352666, -0.01122178, -0.02556491,\n",
       "         -0.03592603, -0.04666705],\n",
       "        [-0.03741231,  0.01323703, -0.04453991,  0.00029878,\n",
       "         -0.03997507, -0.01352666, -0.01122178, -0.02556491,\n",
       "         -0.03592603, -0.04666705],\n",
       "        [-0.03741231,  0.01323703, -0.04453991,  0.00029878,\n",
       "         -0.03997507, -0.01352666, -0.01122178, -0.02556491,\n",
       "         -0.03592603, -0.04666705],\n",
       "        [-0.03741231,  0.01323703, -0.04453991,  0.00029878,\n",
       "         -0.03997507, -0.01352666, -0.01122178, -0.02556491,\n",
       "         -0.03592603, -0.04666705]],\n",
       "\n",
       "       [[-0.04690648, -0.04437856, -0.02405139,  0.01921118,\n",
       "         -0.00761479,  0.00912092,  0.0489172 , -0.02416971,\n",
       "          0.00024564, -0.01714431],\n",
       "        [ 0.03711465,  0.04932915,  0.00330804, -0.01073777,\n",
       "         -0.04564891, -0.04903712, -0.03592753,  0.02817803,\n",
       "          0.01272919,  0.0466398 ],\n",
       "        [-0.02820978,  0.01603475, -0.04342948, -0.03752577,\n",
       "          0.04310134,  0.04873561, -0.0253638 , -0.01022273,\n",
       "         -0.01307159,  0.00450971],\n",
       "        [-0.00636734,  0.04217055, -0.00230851, -0.01511445,\n",
       "          0.03711655, -0.00947821,  0.01210497, -0.01476111,\n",
       "         -0.04519782, -0.01922667],\n",
       "        [ 0.03750003, -0.04060112, -0.01830434,  0.03705451,\n",
       "         -0.0022426 , -0.02042744, -0.00679182,  0.03037429,\n",
       "          0.04763988, -0.0349267 ],\n",
       "        [-0.03741231,  0.01323703, -0.04453991,  0.00029878,\n",
       "         -0.03997507, -0.01352666, -0.01122178, -0.02556491,\n",
       "         -0.03592603, -0.04666705],\n",
       "        [-0.03741231,  0.01323703, -0.04453991,  0.00029878,\n",
       "         -0.03997507, -0.01352666, -0.01122178, -0.02556491,\n",
       "         -0.03592603, -0.04666705],\n",
       "        [-0.03741231,  0.01323703, -0.04453991,  0.00029878,\n",
       "         -0.03997507, -0.01352666, -0.01122178, -0.02556491,\n",
       "         -0.03592603, -0.04666705]],\n",
       "\n",
       "       [[-0.04690648, -0.04437856, -0.02405139,  0.01921118,\n",
       "         -0.00761479,  0.00912092,  0.0489172 , -0.02416971,\n",
       "          0.00024564, -0.01714431],\n",
       "        [ 0.03711465,  0.04932915,  0.00330804, -0.01073777,\n",
       "         -0.04564891, -0.04903712, -0.03592753,  0.02817803,\n",
       "          0.01272919,  0.0466398 ],\n",
       "        [-0.02820978,  0.01603475, -0.04342948, -0.03752577,\n",
       "          0.04310134,  0.04873561, -0.0253638 , -0.01022273,\n",
       "         -0.01307159,  0.00450971],\n",
       "        [-0.00636734,  0.04217055, -0.00230851, -0.01511445,\n",
       "          0.03711655, -0.00947821,  0.01210497, -0.01476111,\n",
       "         -0.04519782, -0.01922667],\n",
       "        [-0.03900791,  0.04970073,  0.01551764,  0.04855099,\n",
       "          0.04380146,  0.03849829, -0.01574381, -0.00937223,\n",
       "         -0.0260278 , -0.01223405],\n",
       "        [-0.03741231,  0.01323703, -0.04453991,  0.00029878,\n",
       "         -0.03997507, -0.01352666, -0.01122178, -0.02556491,\n",
       "         -0.03592603, -0.04666705],\n",
       "        [-0.03741231,  0.01323703, -0.04453991,  0.00029878,\n",
       "         -0.03997507, -0.01352666, -0.01122178, -0.02556491,\n",
       "         -0.03592603, -0.04666705],\n",
       "        [-0.03741231,  0.01323703, -0.04453991,  0.00029878,\n",
       "         -0.03997507, -0.01352666, -0.01122178, -0.02556491,\n",
       "         -0.03592603, -0.04666705]],\n",
       "\n",
       "       [[-0.00912432,  0.00070797,  0.00731875,  0.0010312 ,\n",
       "         -0.00745323,  0.04713711, -0.01886073,  0.00248748,\n",
       "          0.04285559,  0.04381962],\n",
       "        [ 0.04333014,  0.02350302, -0.02824965,  0.01726067,\n",
       "          0.00651807, -0.0306138 , -0.03183967,  0.01574612,\n",
       "          0.03968767,  0.0188956 ],\n",
       "        [ 0.01087499,  0.04255767,  0.0194409 , -0.0078578 ,\n",
       "          0.02253446,  0.00120435,  0.04572319,  0.03253949,\n",
       "         -0.00248928, -0.00555529],\n",
       "        [-0.01828529, -0.01818435,  0.02403356,  0.0450044 ,\n",
       "         -0.01886544,  0.04500891, -0.04477687,  0.00639769,\n",
       "          0.02108623, -0.02160677],\n",
       "        [ 0.04815261,  0.003184  , -0.04451776,  0.00209793,\n",
       "          0.01212689, -0.02208805, -0.02863873, -0.01250305,\n",
       "         -0.01275686, -0.01152377],\n",
       "        [-0.03741231,  0.01323703, -0.04453991,  0.00029878,\n",
       "         -0.03997507, -0.01352666, -0.01122178, -0.02556491,\n",
       "         -0.03592603, -0.04666705],\n",
       "        [-0.03741231,  0.01323703, -0.04453991,  0.00029878,\n",
       "         -0.03997507, -0.01352666, -0.01122178, -0.02556491,\n",
       "         -0.03592603, -0.04666705],\n",
       "        [-0.03741231,  0.01323703, -0.04453991,  0.00029878,\n",
       "         -0.03997507, -0.01352666, -0.01122178, -0.02556491,\n",
       "         -0.03592603, -0.04666705]],\n",
       "\n",
       "       [[ 0.03546289, -0.01695396, -0.04018155,  0.04487221,\n",
       "          0.00270351,  0.03056569,  0.03792664, -0.02376466,\n",
       "         -0.03267252,  0.03409724],\n",
       "        [-0.02054631, -0.0261662 , -0.0266627 , -0.03978497,\n",
       "         -0.00854658, -0.00860007,  0.00467483,  0.00609639,\n",
       "          0.04831251,  0.03521805],\n",
       "        [-0.01925987,  0.01913122, -0.00855404,  0.03759426,\n",
       "          0.02833695,  0.04550413, -0.01188703,  0.03260633,\n",
       "         -0.03631008, -0.04753987],\n",
       "        [-0.00636734,  0.04217055, -0.00230851, -0.01511445,\n",
       "          0.03711655, -0.00947821,  0.01210497, -0.01476111,\n",
       "         -0.04519782, -0.01922667],\n",
       "        [-0.03741231,  0.01323703, -0.04453991,  0.00029878,\n",
       "         -0.03997507, -0.01352666, -0.01122178, -0.02556491,\n",
       "         -0.03592603, -0.04666705],\n",
       "        [-0.03741231,  0.01323703, -0.04453991,  0.00029878,\n",
       "         -0.03997507, -0.01352666, -0.01122178, -0.02556491,\n",
       "         -0.03592603, -0.04666705],\n",
       "        [-0.03741231,  0.01323703, -0.04453991,  0.00029878,\n",
       "         -0.03997507, -0.01352666, -0.01122178, -0.02556491,\n",
       "         -0.03592603, -0.04666705],\n",
       "        [-0.03741231,  0.01323703, -0.04453991,  0.00029878,\n",
       "         -0.03997507, -0.01352666, -0.01122178, -0.02556491,\n",
       "         -0.03592603, -0.04666705]]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(padded_sentences)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
